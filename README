IMPORTANT INFORMATION

This tool uses a development version of the DeryaSE Engine. You are strongly adviced NOT to use it for other porpuses other than running this tool, as it has not been tested for wider use.
For the same reason, you should use this tool under Linux, as it will not compile properly on other operating systems.


REQUIREMENTS:

- A complete gnu C++ compiler
- The MPI library installed
- TIFFLib installed
- A python interpreter
- For data analysis, the R interpreter


INSTALLING

The installer will download required data from the WorldPop database.
Data for one country could range within 5-10Gb.
Downloading might take a long time depending on your connection.
You can repeat the install operation for different countries.

- Edit the install.sh file and modify the following parameters:
  CORES: the number of cores used by each simulation.
  GRIDRES: the resolution in km.
  COUNTRY: the name of the country of interest.
  OUTDIR: name of the directory where to store results:
          this will be a sub directory of the Output directory.

- Run the installer with
  bash install.sh



SET UP

Once installed, move to the 'Master' directory:

cd Master

Edit the 'Makefile' to alter the following variables:
CORES : the number of cores each run will use.
COUNTRY: the country you want to work with
OUTDIR: the directory where executable and data should be stored.
        This will be a sub-directory of 'Output'.

Edit the 'config.py' file and alter the parameters of the country you intend
        to work with.  The 'Default' country can be used as a blueprint.
		You only need to specify values that differ from the 'Default' values.

Now use the make command as follows:

make prepare  # This will remove any pre-existing data in the target output directory.
              # Use with caution.

make  # This will generate three executables that can be used to run specific conditions
      # or to fit to specific data



EXECUTING

Move to the chosen output directory

cd ../Output/XYZ

where XYZ represents the name of the output directory chosen during the SET UP phase.
There are two python scripts in the directory:

- multirun.py

  It is used to run simulations with given parameters.  Altering the 'for' cycle range
  will alter how many simulations are run.


- fitting.py

  It is used to run a fit parameters to a set of data.


Edit the file 'script.sh' and comment out the script that you want to ignore.
Adapt the script file to your cluster and specify the correct number of processes if 
required.  Submit.



NOTES about fitting:

Choose the number of processors (cores) you want to use for a single simulation.  This 
is typically the number of cores of one node.  You can now use multiple nodes for parallel
fitting by using replicas.  For instance, if the cluster has nodes with 16 cores and you 
wish to use 5 nodes for parallel fitting, you can modify the script.sh file as:

#PBS -l nodes=5:ppn=16

or 

#SBATCH --nodes=5
#SBATCH --ntasks-per-node=16

depending on the node engine the cluster uses.  You can then modify the 'fitting.sh' file as:

os.system( "cd Base; mpirun -np 16 ./runderyaSEwrite --replicate 5 1; cd .." )
os.system( "cd Fits;  mpirun -np 16 ./runderyaSEfit --replicate 5 1; cd .." )


The command
