REQUIREMENTS:

- A complete gnu C++ compiler
- LibTiff
- libblas, liblapack
- The MPI library installed
- A python interpreter
- For data analysis, the R interpreter


INSTALLING

The installer will download and install the required engine. 
This will be installed locally in the directory ~/bin/DeryaSE/

Following this, the installer will download required data from the 
WorldPop database.  Data for one country could range within 5-10Gb.
Downloading might take a long time depending on your connection.
It will also build coarsed grained maps and prepare for parallel
simulations according to the number of cores specified in the 
installation script.
You can repeat the install operation for different countries or
for different number of cores or grid resolutions.

How to install:

- Edit the install.sh file and modify the following parameters:
  CORES: the number of cores used by each simulation.
  GRIDRES: the resolution in km.
  COUNTRY: the name of the country of interest.

- Run the installer with
  bash install.sh

If the installer fails because some tiff files from the WorldPop
website are missing, just relaunch it as normal: it will skip 
files already downloaded and attempt downloading the missing files.



SET UP

Once installed, move to the 'Main' directory:

cd Main

Edit the submission scripts 'scriptfits.sh' and 'scriptruns.sh' to
match your cluster submission engine, module requirements and syntax.
In particular:

MPIRUN  should contain the command to launch a parallel mpi job

REPLICAS should be set to the number of replicas you wish to execute
          for the parallel SMC fitting procedure (scriptfits only).



Move now to the 'Scenarios' directory:

cd ../Scenarios

Generate a new scenarios with the command:

bash makeScenarios MYNEWSCENARIO

where MYNEWSCENARIO is a name of your choice for a new scenarios
Change to the new scenario directory

cd MYNEWSCENARIO

Edit the 'config.py' file and alter the parameters of the country you intend
to work with.  The 'Default' country can be used as a blueprint.  The number
of cores should be set to the number of cores specified during installation.
You only need to specify values that differ from the 'Default' values.

Now use the make command as follows:

make write  # This will generate an executable that will generate the mobility data required
				for the simulations

make fits   # This will generate an executable that will implement the fitting procedure



EXECUTING

Move to the 'Output' directory

cd Output

Submit the fitting script following your cluster submission engine syntax.  For instance:

qsub -cwd -N myscenario  scriptfits.sh

OR

sbatch -D . -J myscenario  scriptfits.sh




NOTES about fitting:

You can use multiple nodes for parallel fitting by using replicas.  The number of replicas
should be an integer divisor of the number of processes.  For instance, suppose that you want
to use 10 cluster nodes, each having 16 cores.  That gives a total of 160 processes.
You can use 5 replicas, 10 replicas, but not 7 replicas.  For efficiency, you might want to 
have one replica per node, thus running 10 parallel replicas each using 16 cores.
You will only need to alter the 'scriptfits.sh' file with

  REPLICAS=10

and, according to the node manager of your cluster, either

  #PBS  -l nodes=10:ppm=16

or 

  #SBATCH --nodes=10
  #SBATCH --ntasks-per-node=16




